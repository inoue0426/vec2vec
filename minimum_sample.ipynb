{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd87a0e-a2c1-46ad-b2db-dea9846a7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from train import training_loop_\n",
    "from utils.utils import *\n",
    "import toml\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import accelerate\n",
    "from utils.collate import MultiencoderTokenizedDataset, TokenizedCollator\n",
    "from utils.model_utils import get_sentence_embedding_dimension, load_encoder\n",
    "from utils.streaming_utils import load_streaming_embeddings, process_batch\n",
    "from translators.Discriminator import Discriminator\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from utils.gan import LeastSquaresGAN, RelativisticGAN, VanillaGAN\n",
    "from utils.eval_utils import EarlyStopper, eval_loop_\n",
    "from utils.wandb_logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468f2740-3ad6-4b41-b624-4bc219e09127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(seed=5,\n",
       "          sampling_seed=5,\n",
       "          train_dataset_seed=10,\n",
       "          val_dataset_seed=42,\n",
       "          normalize_embeddings=True,\n",
       "          mixed_precision='fp16',\n",
       "          weight_init='kaiming',\n",
       "          dataset='nq',\n",
       "          max_seq_length=64,\n",
       "          unsup_emb='stella',\n",
       "          sup_emb='gte',\n",
       "          n_embs_per_batch=1,\n",
       "          finetune_mode=False,\n",
       "          noise_level=0.0,\n",
       "          style='res_mlp',\n",
       "          norm_style='batch',\n",
       "          depth=3,\n",
       "          transform_depth=4,\n",
       "          d_adapter=1024,\n",
       "          d_hidden=1024,\n",
       "          d_transform=1024,\n",
       "          use_small_output_adapters=False,\n",
       "          use_residual_adapters=True,\n",
       "          gan_style='least_squares',\n",
       "          disc_depth=5,\n",
       "          disc_dim=1024,\n",
       "          use_residual=True,\n",
       "          bs=256,\n",
       "          gradient_accumulation_steps=1,\n",
       "          lr=2e-05,\n",
       "          no_scheduler=True,\n",
       "          max_grad_norm=1000.0,\n",
       "          loss_coefficient_reverse_rec=0.0,\n",
       "          loss_coefficient_rec=1.0,\n",
       "          loss_coefficient_vsp=1.0,\n",
       "          loss_coefficient_cc_trans=10.0,\n",
       "          loss_coefficient_cc_rec=0.0,\n",
       "          loss_coefficient_cc_vsp=10.0,\n",
       "          loss_coefficient_r1_penalty=0.0,\n",
       "          warmup_length=2000,\n",
       "          patience=20,\n",
       "          min_delta=0.0,\n",
       "          min_epochs=80,\n",
       "          disc_lr=1e-05,\n",
       "          eps=6.25e-10,\n",
       "          smooth=0.9,\n",
       "          loss_coefficient_disc=1.0,\n",
       "          loss_coefficient_gen=1.0,\n",
       "          loss_coefficient_latent_gen=1.0,\n",
       "          loss_coefficient_similarity_gen=0.0,\n",
       "          val_size=4096,\n",
       "          val_bs=1024,\n",
       "          top_k_size=1024,\n",
       "          top_k_batches=4,\n",
       "          k=16,\n",
       "          heatmap_size=64,\n",
       "          use_wandb=True,\n",
       "          wandb_project='unsupervised_disc',\n",
       "          wandb_name='unsupervised',\n",
       "          load_dir='./finetuning_unsupervised/n:100000,e:10,s:n_double,d:4,d:4,d:64/',\n",
       "          save_dir='./finetuning_unsupervised/{}/',\n",
       "          force_dump=True,\n",
       "          num_points=10,\n",
       "          epochs=10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dict = toml.load(f\"configs/unsupervised.toml\")\n",
    "cfg = SimpleNamespace(**{k: v for d in cfg_dict.values() for k, v in d.items()})\n",
    "cfg.num_points = 10\n",
    "cfg.epochs = 10\n",
    "use_val_set = hasattr(cfg, \"val_size\")\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5af078b-d009-4d55-87a6-bd0db38e53ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(cfg.seed)\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "torch.cuda.manual_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76702a80-2b24-4db2-acfa-ace4fcb4f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33minoue0426\u001b[0m (\u001b[33mSanderLab\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/yoshi/code/vec2vec/wandb/run-20251112_143457-mqyywzpm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/SanderLab/unsupervised_disc/runs/mqyywzpm' target=\"_blank\">unsupervised</a></strong> to <a href='https://wandb.ai/SanderLab/unsupervised_disc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/SanderLab/unsupervised_disc' target=\"_blank\">https://wandb.ai/SanderLab/unsupervised_disc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/SanderLab/unsupervised_disc/runs/mqyywzpm' target=\"_blank\">https://wandb.ai/SanderLab/unsupervised_disc/runs/mqyywzpm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Experiment: unsupervised\n"
     ]
    }
   ],
   "source": [
    "mp = \"no\"\n",
    "accelerator = accelerate.Accelerator(\n",
    "    mixed_precision=mp,  # None „Å´„Åó„Å™„ÅÑ\n",
    "    gradient_accumulation_steps=cfg.gradient_accumulation_steps,\n",
    ")\n",
    "\n",
    "# https://github.com/huggingface/transformers/issues/26548\n",
    "accelerator.dataloader_config.dispatch_batches = False\n",
    "\n",
    "if hasattr(cfg, \"force_wandb_name\") and cfg.force_wandb_name:\n",
    "    save_dir = cfg.save_dir.format(cfg.wandb_name)\n",
    "else:\n",
    "    # unknown_cfg „Çí‰Ωø„Çè„Åö„ÄÅcfg ÂÜÖ„ÅÆÊó¢Â≠òÂÄ§„Å†„Åë„Åß wandb_name „ÇíÊ±∫ÂÆö\n",
    "    if not hasattr(cfg, \"wandb_name\") or cfg.wandb_name is None:\n",
    "        cfg.wandb_name = \"default_run\"  # ‰ªªÊÑè„ÅÆ„Éá„Éï„Ç©„É´„ÉàÂêç\n",
    "    save_dir = cfg.save_dir.format(\n",
    "        cfg.latent_dims if hasattr(cfg, \"latent_dims\") else cfg.wandb_name\n",
    "    )\n",
    "\n",
    "logger = Logger(\n",
    "    project=cfg.wandb_project,\n",
    "    name=cfg.wandb_name,\n",
    "    dummy=(cfg.wandb_project is None) or not (cfg.use_wandb),\n",
    "    config=cfg,\n",
    ")\n",
    "\n",
    "print(\"Running Experiment:\", cfg.wandb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b471e078-2f8f-4968-b9a9-fae1b0f08cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "sup_encs = {\n",
    "    cfg.sup_emb: load_encoder(\n",
    "        cfg.sup_emb,\n",
    "        mixed_precision=(\n",
    "            cfg.mixed_precision if hasattr(cfg, \"mixed_precision\") else None\n",
    "        ),\n",
    "    )\n",
    "}\n",
    "encoder_dims = {cfg.sup_emb: get_sentence_embedding_dimension(sup_encs[cfg.sup_emb])}\n",
    "translator = load_n_translator(cfg, encoder_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61db1575-541c-4a8c-a99f-a343af6e4b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n",
      "initializing <class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "unsup_enc = {\n",
    "    cfg.unsup_emb: load_encoder(\n",
    "        cfg.unsup_emb,\n",
    "        mixed_precision=(\n",
    "            cfg.mixed_precision if hasattr(cfg, \"mixed_precision\") else None\n",
    "        ),\n",
    "    )\n",
    "}\n",
    "unsup_dim = {cfg.unsup_emb: get_sentence_embedding_dimension(unsup_enc[cfg.unsup_emb])}\n",
    "translator.add_encoders(unsup_dim, overwrite_embs=[cfg.unsup_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2c8e70-a94c-4136-9e7c-dcfcb7c024f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 workers and 5332023 datapoints\n"
     ]
    }
   ],
   "source": [
    "cfg.num_params = sum(x.numel() for x in translator.parameters())\n",
    "num_workers = min(get_num_proc(), 8)\n",
    "dset = load_streaming_embeddings(cfg.dataset)\n",
    "print(f\"Using {num_workers} workers and {len(dset)} datapoints\")\n",
    "\n",
    "dset_dict = dset.train_test_split(test_size=cfg.val_size, seed=cfg.val_dataset_seed)\n",
    "dset = dset_dict[\"train\"]\n",
    "valset = dset_dict[\"test\"]\n",
    "\n",
    "assert hasattr(cfg, \"num_points\") or hasattr(cfg, \"unsup_points\")\n",
    "dset = dset.shuffle(seed=cfg.train_dataset_seed)\n",
    "if hasattr(cfg, \"num_points\"):\n",
    "    assert cfg.num_points > 0 and cfg.num_points <= len(dset) // 2\n",
    "    supset = dset.select(range(cfg.num_points))\n",
    "    unsupset = dset.select(range(cfg.num_points, cfg.num_points * 2))\n",
    "elif hasattr(cfg, \"unsup_points\"):\n",
    "    unsupset = dset.select(range(min(cfg.unsup_points, len(dset))))\n",
    "    supset = dset.select(\n",
    "        range(min(cfg.unsup_points, len(dset)), len(dset) - len(unsupset))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd41c7b-df88-4888-953f-f47ece1ece2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] Device: MPS, pin_memory=False\n"
     ]
    }
   ],
   "source": [
    "# --- „Éá„Éê„Ç§„Çπ„Å´Âøú„Åò„Å¶ pin_memory „ÇíË®≠ÂÆö ---\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "pin_memory_flag = True if use_cuda else False\n",
    "\n",
    "print(\n",
    "    f\"[Init] Device: {'CUDA' if use_cuda else ('MPS' if use_mps else 'CPU')}, pin_memory={pin_memory_flag}\"\n",
    ")\n",
    "\n",
    "# --- Dataset „ÅÆ‰ΩúÊàê ---\n",
    "supset = MultiencoderTokenizedDataset(\n",
    "    dataset=supset,\n",
    "    encoders=sup_encs,\n",
    "    n_embs_per_batch=cfg.n_embs_per_batch,\n",
    "    batch_size=cfg.bs,\n",
    "    max_length=cfg.max_seq_length,\n",
    "    seed=cfg.sampling_seed,\n",
    ")\n",
    "\n",
    "unsupset = MultiencoderTokenizedDataset(\n",
    "    dataset=unsupset,\n",
    "    encoders=unsup_enc,\n",
    "    n_embs_per_batch=1,\n",
    "    batch_size=cfg.bs,\n",
    "    max_length=cfg.max_seq_length,\n",
    "    seed=cfg.sampling_seed,\n",
    ")\n",
    "\n",
    "# --- DataLoader „ÅÆ‰ΩúÊàê ---\n",
    "sup_dataloader = DataLoader(\n",
    "    supset,\n",
    "    batch_size=cfg.bs,\n",
    "    num_workers=num_workers // 2,\n",
    "    shuffle=True,\n",
    "    pin_memory=pin_memory_flag,\n",
    "    prefetch_factor=None,\n",
    "    collate_fn=TokenizedCollator(),\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "unsup_dataloader = DataLoader(\n",
    "    unsupset,\n",
    "    batch_size=cfg.bs,\n",
    "    num_workers=num_workers // 2,\n",
    "    shuffle=True,\n",
    "    pin_memory=pin_memory_flag,\n",
    "    prefetch_factor=None,\n",
    "    collate_fn=TokenizedCollator(),\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "if use_val_set:\n",
    "    valset = MultiencoderTokenizedDataset(\n",
    "        dataset=valset,\n",
    "        encoders={**unsup_enc, **sup_encs},\n",
    "        n_embs_per_batch=2,\n",
    "        batch_size=cfg.val_bs,\n",
    "        max_length=cfg.max_seq_length,\n",
    "        seed=cfg.sampling_seed,\n",
    "    )\n",
    "\n",
    "    valloader = DataLoader(\n",
    "        valset,\n",
    "        batch_size=cfg.val_bs if hasattr(cfg, \"val_bs\") else cfg.bs,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=pin_memory_flag,\n",
    "        prefetch_factor=(8 if num_workers > 0 else None),\n",
    "        collate_fn=TokenizedCollator(),\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valloader = accelerator.prepare(valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93a496e1-3b46-4021-be4b-232b9014be3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.collate.MultiencoderTokenizedDataset at 0x33c58c6d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e9736e-1027-400c-8d67-60d3633d9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(\n",
    "    translator.parameters(), lr=cfg.lr, fused=False, betas=(0.5, 0.999)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08d08fc4-96f6-4955-b047-560f2e235ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "disc = Discriminator(\n",
    "    latent_dim=translator.in_adapters[cfg.unsup_emb].in_dim,\n",
    "    discriminator_dim=cfg.disc_dim,\n",
    "    depth=cfg.disc_depth,\n",
    "    weight_init=cfg.weight_init,\n",
    ")\n",
    "disc_opt = torch.optim.Adam(\n",
    "    disc.parameters(), lr=cfg.disc_lr, eps=cfg.eps, betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "cfg.num_disc_params = sum(x.numel() for x in disc.parameters())\n",
    "# print(f\"Number of discriminator parameters:\", cfg.num_disc_params)\n",
    "######################################################################################\n",
    "sup_disc = Discriminator(\n",
    "    latent_dim=translator.in_adapters[cfg.sup_emb].in_dim,\n",
    "    discriminator_dim=cfg.disc_dim,\n",
    "    depth=cfg.disc_depth,\n",
    ")\n",
    "sup_disc_opt = torch.optim.Adam(\n",
    "    sup_disc.parameters(), lr=cfg.disc_lr, eps=cfg.eps, betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "cfg.num_sup_disc_params = sum(x.numel() for x in sup_disc.parameters())\n",
    "# print(f\"Number of supervised discriminator parameters:\", cfg.num_sup_disc_params)\n",
    "# print(sup_disc)\n",
    "######################################################################################\n",
    "latent_disc = Discriminator(\n",
    "    latent_dim=cfg.d_adapter,\n",
    "    discriminator_dim=cfg.disc_dim,\n",
    "    depth=cfg.disc_depth,\n",
    "    weight_init=cfg.weight_init,\n",
    ")\n",
    "latent_disc_opt = torch.optim.RMSprop(\n",
    "    latent_disc.parameters(), lr=cfg.disc_lr, eps=cfg.eps\n",
    ")\n",
    "cfg.num_latent_disc_params = sum(x.numel() for x in latent_disc.parameters())\n",
    "# print(f\"Number of latent discriminator parameters:\", cfg.num_latent_disc_params)\n",
    "# print(latent_disc)\n",
    "latent_disc_opt = torch.optim.Adam(\n",
    "    latent_disc.parameters(), lr=cfg.disc_lr, eps=cfg.eps, betas=(0.5, 0.999)\n",
    ")\n",
    "######################################################################################\n",
    "similarity_disc = Discriminator(\n",
    "    latent_dim=cfg.bs,\n",
    "    discriminator_dim=cfg.disc_dim,\n",
    "    depth=cfg.disc_depth,\n",
    "    weight_init=cfg.weight_init,\n",
    ")\n",
    "similarity_disc_opt = torch.optim.RMSprop(\n",
    "    similarity_disc.parameters(), lr=cfg.disc_lr, eps=cfg.eps\n",
    ")\n",
    "cfg.num_similarity_disc_params = sum(x.numel() for x in similarity_disc.parameters())\n",
    "# print(f\"Number of similarity discriminator parameters:\", cfg.num_similarity_disc_params)\n",
    "# print(similarity_disc)\n",
    "similarity_disc_opt = torch.optim.Adam(\n",
    "    similarity_disc.parameters(), lr=cfg.disc_lr, eps=cfg.eps, betas=(0.5, 0.999)\n",
    ")\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a03f38b-6c41-406f-992b-efe26f2146cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_epochs = int(np.ceil(cfg.epochs))\n",
    "steps_per_epoch = len(supset) // cfg.bs\n",
    "total_steps = steps_per_epoch * cfg.epochs / cfg.gradient_accumulation_steps\n",
    "warmup_length = cfg.warmup_length if hasattr(cfg, \"warmup_length\") else 100\n",
    "\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_length:\n",
    "        return min(1, step / warmup_length)\n",
    "    else:\n",
    "        if hasattr(cfg, \"no_scheduler\") and cfg.no_scheduler:\n",
    "            return 1\n",
    "        return 1 - (step - warmup_length) / max(1, total_steps - warmup_length)\n",
    "\n",
    "\n",
    "scheduler = LambdaLR(opt, lr_lambda=lr_lambda)\n",
    "disc_scheduler = LambdaLR(disc_opt, lr_lambda=lr_lambda)\n",
    "sup_disc_scheduler = LambdaLR(sup_disc_opt, lr_lambda=lr_lambda)\n",
    "latent_disc_scheduler = LambdaLR(latent_disc_opt, lr_lambda=lr_lambda)\n",
    "similarity_disc_scheduler = LambdaLR(similarity_disc_opt, lr_lambda=lr_lambda)\n",
    "\n",
    "if cfg.finetune_mode:\n",
    "    assert hasattr(cfg, \"load_dir\")\n",
    "    print(f\"Loading models from {cfg.load_dir}...\")\n",
    "    translator.load_state_dict(\n",
    "        torch.load(cfg.load_dir + \"model.pt\", map_location=\"cpu\"), strict=False\n",
    "    )\n",
    "    disc.load_state_dict(torch.load(cfg.load_dir + \"disc.pt\", map_location=\"cpu\"))\n",
    "\n",
    "translator, opt, scheduler = accelerator.prepare(translator, opt, scheduler)\n",
    "disc, disc_opt, disc_scheduler = accelerator.prepare(disc, disc_opt, disc_scheduler)\n",
    "sup_disc, sup_disc_opt, sup_disc_scheduler = accelerator.prepare(\n",
    "    sup_disc, sup_disc_opt, sup_disc_scheduler\n",
    ")\n",
    "latent_disc, latent_disc_opt, latent_disc_scheduler = accelerator.prepare(\n",
    "    latent_disc, latent_disc_opt, latent_disc_scheduler\n",
    ")\n",
    "similarity_disc, similarity_disc_opt, similarity_disc_scheduler = accelerator.prepare(\n",
    "    similarity_disc, similarity_disc_opt, similarity_disc_scheduler\n",
    ")\n",
    "sup_dataloader, unsup_dataloader = accelerator.prepare(sup_dataloader, unsup_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46bfbb59-26e5-4da5-8b85-1d49a0a26507",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.gan_style == \"vanilla\":\n",
    "    gan_cls = VanillaGAN\n",
    "elif cfg.gan_style == \"least_squares\":\n",
    "    gan_cls = LeastSquaresGAN\n",
    "elif cfg.gan_style == \"relativistic\":\n",
    "    gan_cls = RelativisticGAN\n",
    "else:\n",
    "    raise ValueError(f\"Unknown GAN style: {cfg.gan_style}\")\n",
    "latent_gan = gan_cls(\n",
    "    cfg=cfg,\n",
    "    generator=translator,\n",
    "    discriminator=latent_disc,\n",
    "    discriminator_opt=latent_disc_opt,\n",
    "    discriminator_scheduler=latent_disc_scheduler,\n",
    "    accelerator=accelerator,\n",
    ")\n",
    "similarity_gan = gan_cls(\n",
    "    cfg=cfg,\n",
    "    generator=translator,\n",
    "    discriminator=similarity_disc,\n",
    "    discriminator_opt=similarity_disc_opt,\n",
    "    discriminator_scheduler=similarity_disc_scheduler,\n",
    "    accelerator=accelerator,\n",
    ")\n",
    "gan = gan_cls(\n",
    "    cfg=cfg,\n",
    "    generator=translator,\n",
    "    discriminator=disc,\n",
    "    discriminator_opt=disc_opt,\n",
    "    discriminator_scheduler=disc_scheduler,\n",
    "    accelerator=accelerator,\n",
    ")\n",
    "sup_gan = gan_cls(\n",
    "    cfg=cfg,\n",
    "    generator=translator,\n",
    "    discriminator=sup_disc,\n",
    "    discriminator_opt=sup_disc_opt,\n",
    "    discriminator_scheduler=sup_disc_scheduler,\n",
    "    accelerator=accelerator,\n",
    ")\n",
    "\n",
    "sup_iter = None\n",
    "if hasattr(cfg, \"unsup_points\"):\n",
    "    sup_iter = iter(sup_dataloader)\n",
    "\n",
    "if hasattr(cfg, \"val_size\") and hasattr(cfg, \"patience\") and hasattr(cfg, \"min_delta\"):\n",
    "    early_stopper = EarlyStopper(\n",
    "        patience=cfg.patience, min_delta=cfg.min_delta, increase=False\n",
    "    )\n",
    "    early_stopping = True\n",
    "else:\n",
    "    early_stopping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333f4bcf-f641-437e-98f9-e11e0912ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_val_summary(epoch, val_res):\n",
    "    print(f\"\\nüìä ===== Validation Summary (Epoch {epoch + 1}) =====\")\n",
    "\n",
    "    # ÂÜçÊßãÊàê (reconstruction) Á≥ª\n",
    "    rec_gte = val_res.get(\"val/rec_gte_cos\", None)\n",
    "    rec_stella = val_res.get(\"val/rec_stella_cos\", None)\n",
    "    if rec_gte is not None or rec_stella is not None:\n",
    "        print(f\"  üîπ Reconstruction Cosine Similarity:\")\n",
    "        if rec_gte is not None:\n",
    "            print(f\"    - GTE self-cosine:     {rec_gte:.4f}\")\n",
    "        if rec_stella is not None:\n",
    "            print(f\"    - STELLA self-cosine:  {rec_stella:.4f}\")\n",
    "\n",
    "    # ÁøªË®≥ (translation) Á≥ª\n",
    "    trans_cos = val_res.get(\"val/gte_stella_cos\", None)\n",
    "    trans_vsp = val_res.get(\"val/gte_stella_vsp\", None)\n",
    "    if trans_cos is not None or trans_vsp is not None:\n",
    "        print(f\"  üîπ GTE ‚Üí STELLA translation:\")\n",
    "        if trans_cos is not None:\n",
    "            print(f\"    - Cosine: {trans_cos:.4f}\")\n",
    "        if trans_vsp is not None:\n",
    "            print(f\"    - VSP:    {trans_vsp:.4f}\")\n",
    "\n",
    "    trans_cos2 = val_res.get(\"val/stella_gte_cos\", None)\n",
    "    trans_vsp2 = val_res.get(\"val/stella_gte_vsp\", None)\n",
    "    if trans_cos2 is not None or trans_vsp2 is not None:\n",
    "        print(f\"  üîπ STELLA ‚Üí GTE translation:\")\n",
    "        if trans_cos2 is not None:\n",
    "            print(f\"    - Cosine: {trans_cos2:.4f}\")\n",
    "        if trans_vsp2 is not None:\n",
    "            print(f\"    - VSP:    {trans_vsp2:.4f}\")\n",
    "\n",
    "    # Accuracy Á≥ª\n",
    "    top1 = val_res.get(\"val/gte_stella_top_1_acc (avg. 4 batches)\", None)\n",
    "    top16 = val_res.get(\"val/gte_stella_top_16_acc (avg. 4 batches)\", None)\n",
    "    rank = val_res.get(\"val/gte_stella_rank (avg. 4 batches)\", None)\n",
    "    if top1 is not None or top16 is not None or rank is not None:\n",
    "        print(f\"  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\")\n",
    "        if top1 is not None:\n",
    "            print(f\"    - Top-1 Acc:    {top1:.3f}\")\n",
    "        if top16 is not None:\n",
    "            print(f\"    - Top-16 Acc:   {top16:.3f}\")\n",
    "        if rank is not None:\n",
    "            print(f\"    - Avg. Rank:    {rank:.1f}\")\n",
    "\n",
    "    # Rank variance / SE\n",
    "    rank_se = val_res.get(\"val/gte_stella_rank_se (avg. 4 batches)\", None)\n",
    "    if rank_se is not None:\n",
    "        print(f\"    - Rank StdErr:  {rank_se:.3f}\")\n",
    "\n",
    "    print(\"===========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac477c9d-a2a8-4995-9975-77eded49dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/10 =====\n",
      "[Eval] Running validation...\n",
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 1) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 1 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 2/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 2) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 2 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 3/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 3) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 3 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 4/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 4) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 4 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 5/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 5) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 5 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 6/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 6) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 6 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 7/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 7) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 7 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 8/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 8) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:09, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 8 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 9/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 9) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 9 completed.\n",
      "-----------------------------------------\n",
      "\n",
      "===== Epoch 10/10 =====\n",
      "[Eval] Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Validation finished. Processing results...\n",
      "[Eval] Found 18 heatmap metrics.\n",
      "[Eval] Validation metrics collected.\n",
      "\n",
      "üìä ===== Validation Summary (Epoch 10) =====\n",
      "  üîπ Reconstruction Cosine Similarity:\n",
      "    - GTE self-cosine:     0.0683\n",
      "    - STELLA self-cosine:  0.0926\n",
      "  üîπ GTE ‚Üí STELLA translation:\n",
      "    - Cosine: 0.0614\n",
      "    - VSP:    0.3430\n",
      "  üîπ STELLA ‚Üí GTE translation:\n",
      "    - Cosine: 0.0270\n",
      "    - VSP:    0.1270\n",
      "  üîπ Retrieval metrics (GTE‚ÜíSTELLA):\n",
      "    - Top-1 Acc:    0.019\n",
      "    - Top-16 Acc:   0.159\n",
      "    - Avg. Rank:    203.0\n",
      "    - Rank StdErr:  3.406\n",
      "===========================================\n",
      "[Train] Starting training loop for epoch 10\n",
      "[Train] Final epoch detected. Setting max_num_batches = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 10 completed.\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_num_epochs):\n",
    "    print(f\"\\n===== Epoch {epoch + 1}/{max_num_epochs} =====\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    if use_val_set:\n",
    "        print(\"[Eval] Running validation...\")\n",
    "        with torch.no_grad(), accelerator.autocast():\n",
    "            translator.eval()\n",
    "            val_res = {}\n",
    "            recons, trans, heatmap_dict, _, _, _ = eval_loop_(\n",
    "                cfg,\n",
    "                translator,\n",
    "                {**sup_encs, **unsup_enc},\n",
    "                valloader,\n",
    "                device=accelerator.device,\n",
    "            )\n",
    "\n",
    "            print(f\"[Eval] Validation finished. Processing results...\")\n",
    "            for flag, res in recons.items():\n",
    "                for k, v in res.items():\n",
    "                    if k == \"cos\":\n",
    "                        val_res[f\"val/rec_{flag}_{k}\"] = v\n",
    "\n",
    "            for target_flag, d in trans.items():\n",
    "                for flag, res in d.items():\n",
    "                    for k, v in res.items():\n",
    "                        if flag == cfg.unsup_emb and target_flag == cfg.unsup_emb:\n",
    "                            continue\n",
    "                        val_res[f\"val/{flag}_{target_flag}_{k}\"] = v\n",
    "\n",
    "            if len(heatmap_dict) > 0:\n",
    "                print(f\"[Eval] Found {len(heatmap_dict)} heatmap metrics.\")\n",
    "                for k, v in heatmap_dict.items():\n",
    "                    if \"heatmap\" in k and \"top\" not in k:\n",
    "                        val_res[f\"val/{k}\"] = v\n",
    "                    else:\n",
    "                        val_res[f\"val/{k} (avg. {cfg.top_k_batches} batches)\"] = v\n",
    "\n",
    "            translator.train()\n",
    "            print(\"[Eval] Validation metrics collected.\")\n",
    "\n",
    "        # --- Early Stopping ---\n",
    "        if epoch >= getattr(cfg, \"min_epochs\", 0) and early_stopping:\n",
    "            score_values = [v for k, v in val_res.items() if \"top_rank\" in k]\n",
    "            score = np.mean(score_values) if len(score_values) > 0 else 0.0\n",
    "            print(f\"[Eval] Validation score (mean top_rank): {score:.4f}\")\n",
    "\n",
    "            if early_stopper.early_stop(score):\n",
    "                print(\"üõë Early stopping triggered!\")\n",
    "                break\n",
    "            if early_stopper.counter == 0 and score < early_stopper.opt_val:\n",
    "                print(\n",
    "                    f\"[Eval] Saving model ‚Äî new best score ({score:.4f} < {early_stopper.opt_val:.4f})\"\n",
    "                )\n",
    "                save_everything(\n",
    "                    cfg,\n",
    "                    translator,\n",
    "                    opt,\n",
    "                    [gan, sup_gan, latent_gan, similarity_gan],\n",
    "                    save_dir,\n",
    "                )\n",
    "\n",
    "    print_val_summary(epoch, val_res)\n",
    "\n",
    "    # --- Training ---\n",
    "    max_num_batches = None\n",
    "    print(f\"[Train] Starting training loop for epoch {epoch + 1}\")\n",
    "    if epoch + 1 >= max_num_epochs:\n",
    "        max_num_batches = max(1, int((cfg.epochs - epoch) * len(supset) // cfg.bs))\n",
    "        print(\n",
    "            f\"[Train] Final epoch detected. Setting max_num_batches = {max_num_batches}\"\n",
    "        )\n",
    "\n",
    "    sup_iter = training_loop_(\n",
    "        save_dir=save_dir,\n",
    "        accelerator=accelerator,\n",
    "        translator=translator,\n",
    "        gan=gan,\n",
    "        sup_gan=sup_gan,\n",
    "        latent_gan=latent_gan,\n",
    "        similarity_gan=similarity_gan,\n",
    "        sup_dataloader=sup_dataloader,\n",
    "        sup_iter=sup_iter,\n",
    "        unsup_dataloader=unsup_dataloader,\n",
    "        sup_encs=sup_encs,\n",
    "        unsup_enc=unsup_enc,\n",
    "        cfg=cfg,\n",
    "        opt=opt,\n",
    "        scheduler=scheduler,\n",
    "        logger=logger,\n",
    "        max_num_batches=max_num_batches,\n",
    "    )\n",
    "\n",
    "    print(f\"[Train] Epoch {epoch + 1} completed.\")\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a230a-99ca-49d0-9c80-5c27d9a8e11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7da57-a4bb-465b-bb07-ee5e5a8055b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd90c22-5e3f-465e-bfd3-005afafd9723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93c70b-0bca-4d7d-aaf0-4b38a832e691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb26f9-ed3d-4ee8-a112-9b6c34636850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515d59e-8f0c-4e95-b431-34f86c16937e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693004eb-b1b9-43e6-9174-e2255ebd71af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vec2vec",
   "language": "python",
   "name": "vec2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
